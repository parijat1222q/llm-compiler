# Environment configuration for LLM Compiler
# Copy this file to .env and fill in real values before running

# Port where the API server will run
PORT=3000

# OpenAI API Key used by the AI integration module
OPENAI_API_KEY=your-openai-api-key-here

# OpenAI model to use (e.g., gpt-4, gpt-3.5-turbo)
OPENAI_MODEL=gpt-4

# Force JSON response format from OpenAI when supported (true/false)
OPENAI_FORCE_JSON_MODE=true

# Directory where generated projects and zip archives will be placed
OUTPUT_DIR=./output

# Node environment: development or production
NODE_ENV=development
